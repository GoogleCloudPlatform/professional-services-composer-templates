# Copyright 2024 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     https://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# DAG parameters
# mandatory
dag_id: dataflow_tasks_dag
description:
max_active_runs:
catchup: False
schedule_interval: "None"
tags: ["test"]
owner:


# Optional. List imports required outside of task operators
additional_imports:


task_variables:
  variables_file_path: examples/composer_dag_tasks_variables/dataflow_tasks_variables.py


# Define Python functions to be added in your Airflow DAG
custom_python_functions:
  custom_defined_functions:


# Tasks specific configs
# mandatory
tasks:
  - task_id: start_templated_job
    task_type: airflow.providers.google.cloud.operators.dataflow.DataflowTemplatedJobStartOperator
    job_name: job_name
    project_id: project_id
    template: gs://dataflow-templates/latest/Word_Count
    parameters: parameters
    environment: environment
    location: region
    depends_on: 
    trigger_rule : 'none_failed'
  - task_id: start_flex_templated_job
    task_type: airflow.providers.google.cloud.operators.dataflow.DataflowStartFlexTemplateOperator
    location: region
    body: flex_body
    wait_until_finished: True
    depends_on: 
      - start_templated_job
    trigger_rule : 'none_failed'
  - task_id: start_dataflow_job
    task_type: airflow.providers.apache.beam.operators.beam.BeamRunJavaPipelineOperator
    runner: DataflowRunner
    job_class: "org.apache.beam.examples.WordCount"
    jar: java_beam_jar
    pipeline_options: java_beam_pipeline
    dataflow_config : {"check_if_running":"CheckJobRunning.IgnoreJob","location":"us-central1","poll_sleep":10,'job_name':'start_dataflow_job'}
    depends_on: 
      - start_templated_job
    trigger_rule : 'none_failed'
  - task_id: stop_templated_job
    task_type: airflow.providers.google.cloud.operators.dataflow.DataflowStopJobOperator
    location: region
    job_name_prefix: job_name
    depends_on: 
      - start_flex_templated_job
    trigger_rule : 'none_failed'


task_dependency:
  default_task_dependency: True


