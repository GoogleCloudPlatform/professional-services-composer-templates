# Copyright 2024 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     https://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Before configuring YAML and generate DAG, please setup MySQL connection by using Airflow webserver as mentioned:
# https://airflow.apache.org/docs/apache-airflow/1.10.14/howto/connection/mysql.html

# To configure follow the steps mentioned below
# 1. Go to Airflow Webserver
# 2. Go to connections
# 3. Click on + and select MySQL
# 4. Add all the required host, port and other connection details.

# To Export data to GCS using this DAG tmplate please configure the Service account with apporiate roles and access as mentioned:
# https://cloud.google.com/sql/docs/mysql/import-export/import-export-csv#export_data_from

# DAG parameters (mandatory)
dag_id: cloudsql_tasks_dag     
description:
max_active_runs:
catchup: False
schedule_interval: "None"   # mandatory; enclose values within quotes
tags: ["test"]
owner:       


# Optional. List imports required outside of task operators
additional_imports:


task_variables:
  variables_file_path: examples/composer_dag_tasks_variables/cloudsql_tasks_variables.py


# Define Python functions to be added in your Airflow DAG
custom_python_functions:
  custom_defined_functions:
    perform_transformation:
      description: Sample function as an example to perform custom transformation.
      code: |
        def transformation(data):
          """
          Sample function as an example to perform custom transformation.

          Args:
            data: Sample data on which we can perform any transformation.
          
          Returns:
            The data converted into a string format.
          """
          print("Printing sample payload from transformation function: {}".format(data))
          output = str(data)
          return output
    pull_xcom:
      description: Function to pull xcom variables from export GCS task print or use it for other transformations.
      code: |
        def pull_xcom(**kwargs):
          """
          Pulls a value from XCom and prints it.
          """
          ti = kwargs['ti']
          pulled_value = str(ti.xcom_pull(task_ids='export_sales_reporting_table_to_gcs', key='file_details'))
          print(f"Pulled value from XCom: {pulled_value}")
          return pulled_value


# Tasks specific configs
# mandatory
tasks:
  - task_id: cloud_sql_truncate_sales_table_task
    task_type: airflow.providers.google.cloud.operators.cloud_sql.CloudSQLExecuteQueryOperator
    gcp_cloudsql_conn_id: gcp_cloudsql_conn_id
    sql: truncate_sales_table_sql
    trigger_rule : 'all_done'
    depends_on: 
  - task_id: cloud_sql_import_sales_data_from_gcs
    task_type: airflow.providers.google.cloud.operators.cloud_sql.CloudSQLImportInstanceOperator
    instance: composer_instance
    body: import_from_gcs_cloud_sql_body
    trigger_rule : 'all_done'
    depends_on: 
      - cloud_sql_truncate_sales_table_task
  - task_id: cloud_sql_drop_sales_reporting_table_task
    task_type: airflow.providers.google.cloud.operators.cloud_sql.CloudSQLExecuteQueryOperator
    gcp_cloudsql_conn_id: gcp_cloudsql_conn_id
    sql: drop_sales_reporting_table_sql
    trigger_rule : 'all_done'
    depends_on: 
      - cloud_sql_import_sales_data_from_gcs
  - task_id: cloud_sql_create_sales_reporting_table_task
    task_type: airflow.providers.google.cloud.operators.cloud_sql.CloudSQLExecuteQueryOperator
    gcp_cloudsql_conn_id: gcp_cloudsql_conn_id
    sql: create_sales_table_sql
    trigger_rule : 'all_done'
    depends_on: 
      - cloud_sql_drop_sales_reporting_table_task
  - task_id: export_sales_reporting_table_to_gcs
    task_type: airflow.providers.google.cloud.operators.cloud_sql.CloudSQLExportInstanceOperator
    instance: composer_instance
    body: export_to_gcs_cloud_sql_body
    trigger_rule : 'all_done'
    depends_on: 
      - cloud_sql_create_sales_reporting_table_task


task_dependency:
  default_task_dependency: True

