# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# DAG parameters
dag_id: generative_ai_tasks_dag
description: Demonstration of Vertex Generative AI ops on Airflow/Composer
max_active_runs: 1
catchup: False
schedule_interval: "@once"
is_paused_upon_creation: True
tags: ["demo", "vertex_ai", "generative_ai"]

# Default arguments
default_args:
    owner: 'Google'
    retries: 0
    email_on_failure: False
    email_on_retry: False
    depends_on_past: False
    retry_delay: 1
    sla: 55
    execution_timeout: 60
    start_date: '2024-01-01'

# Python functions used by Python operators
custom_python_functions:
  import_functions_from_file: True
  functions_file_path: examples/python_function_files/generative_ai_python_functions.py

# Environment specific configurations
tasks:
    - task_id: training_data_exists_sensor
      task_type: airflow.providers.google.cloud.sensors.gcs.GCSObjectExistenceSensor
      bucket: cloud-samples-data
      object: ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl
      depends_on: None
      trigger_rule: 'all_success'

    - task_id: sft_train_base_task
      task_type: airflow.providers.google.cloud.operators.vertex_ai.generative_model.SupervisedFineTuningTrainOperator
      project_id: cc_var_project_id
      location: cc_var_region
      source_model: cc_var_pro_model
      train_dataset: gs://cloud-samples-data/ai-platform/generative_ai/gemini-1_5/text/sft_train_data.jsonl
      depends_on: training_data_exists_sensor
      trigger_rule: 'all_success'

    - task_id: count_tokens_task
      task_type: airflow.providers.google.cloud.operators.vertex_ai.generative_model.CountTokensOperator
      project_id: cc_var_project_id
      location: cc_var_region
      pretrained_model: '{{ task_instance.xcom_pull(task_ids="sft_train_base_task", key="tuned_model_endpoint_name") }}'
      contents: cc_var_sample_prompt
      depends_on: evaluate_tuned_base_model_task
      trigger_rule: 'all_success'

    - task_id: validate_tokens_task
      task_type: airflow.operators.python.PythonOperator
      python_callable: validate_tokens
      op_kwargs:
        character_budget: '1000'
        token_budget: '500'
        total_billable_characters: '{{ task_instance.xcom_pull(task_ids="count_tokens_task", key="total_billable_characters") }}'
        total_tokens: '{{ task_instance.xcom_pull(task_ids="count_tokens_task", key="total_tokens") }}'
      provide_context: True
      depends_on: count_tokens_task
      trigger_rule: 'all_success'

    - task_id: deterministic_generate_content_task
      task_type: airflow.providers.google.cloud.operators.vertex_ai.generative_model.GenerativeModelGenerateContentOperator
      project_id: cc_var_project_id
      location: cc_var_region
      pretrained_model: '{{ task_instance.xcom_pull(task_ids="sft_train_base_task", key="tuned_model_endpoint_name") }}'
      system_instruction: cc_var_system_instruction
      contents: cc_var_sample_prompt
      generation_config: cc_var_deterministic_gen_config
      tools: []
      depends_on: validate_tokens_task
      trigger_rule: 'all_success'

task_dependency:
  default_task_dependency: True

task_variables:
  # Load variables from a YAML file in GCS. The file should be at:
  # gs://<YOUR_COMPOSER_ENV_NAME>/dag_variables/<variables_file_name>
  import_from_file: True  # Boolean to enable/disable file import
  file_name: generative_ai_tasks_variables.yaml
  environment: dev  # Environment to load from the file