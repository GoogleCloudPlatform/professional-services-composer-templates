# Copyright 2024 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     https://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging
from datetime import datetime, timedelta
from airflow.models import DAG

{%- from 'macros.template' import render_optional_param, format_value, render_task_group, render_task %}

{%- if config_data['task_groups'] and config_data['task_groups'] is defined %}
from airflow.utils.task_group import TaskGroup
{%- endif %}

{#- Start: Contructs imports dynamically based on task_type #}
{%- set task_libraries = {} %} 

{%- for task in config_data['tasks'] %}
  {%- set key = ('.'.join(task['task_type'].split('.')[0:-1]), task['task_type'].split('.')[-1]) %}
  {%- if key not in task_libraries %}
    {%- set _ = task_libraries.update({key: None}) %} 
  {%- endif %}
{%- endfor %}

{%- if config_data.get('task_groups') and config_data['task_groups'] %}
    {%- for group in config_data['task_groups'] %}
    {%- for task in group['tasks'] %}
        {%- set key = ('.'.join(task['task_type'].split('.')[0:-1]), task['task_type'].split('.')[-1]) %}
        {%- if key not in task_libraries %}
        {%- set _ = task_libraries.update({key: None}) %} 
        {%- endif %}
    {%- endfor %}
    {%- endfor %}
{%- endif %}

{#- Start: Additional imports #}
{%- if config_data.get('additional_imports') and config_data['additional_imports'] %}
    {%- for imp in config_data.get('additional_imports', []) %}
{{ imp.module }}
    {%- endfor %}
{%- endif %}

{%- for (module, operator) in task_libraries.keys() %}
from {{ module }} import {{ operator }}
{%- endfor %}
{#- End #}

{%- set config_values = namespace() %}
{%- for key, value in framework_config_values.items() %}
{%- if key == "var_configs" %}
{%- set config_values.var_configs = value %}
{%- endif %}
{%- endfor %}


log = logging.getLogger("airflow")
log.setLevel(logging.INFO)

{#- Start: Processes Python functions definition from the YAML #}
{%- if python_functions.add_functions %}
    {% for function_code in python_functions.functions %}

{{ function_code }}

    {%- endfor %}
{%- endif %}
{# End #}

{#- Start: Processes python variables definition #}
{% if dag_variables.add_variables %}
    {% for variable in dag_variables.variables -%}

{{ variable }}
    {%- endfor %}
{%- endif %}
{#- End #}

{%- if config_values.var_configs["import_from_file"] == True and config_values.var_configs["file_name"] is defined -%}
composer_env_name = os.environ["COMPOSER_ENVIRONMENT"]
composer_env_bucket = os.environ["GCS_BUCKET"]
env_configs = {}

def load_config_from_gcs(bucket_name: str, source_blob_name: str) -> Dict[str, Any]:
    """Downloads a blob from the bucket."""
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(source_blob_name)
    blob.download_to_filename("config.yaml")
    with open("config.yaml") as f:
        config = yaml.safe_load(f)
    return config

run_time_config_data = load_config_from_gcs(
    bucket_name=composer_env_bucket,
    source_blob_name="dag_variables/{{ config_values.var_configs["file_name"] }}"
)

if type(run_time_config_data["{{ config_values.var_configs["environment"] }}"]) is dict:
    env_configs = run_time_config_data["{{ config_values.var_configs["environment"] }}"]


{%- elif config_values.var_configs["import_from_file"] == False %}
{%- set env_configs = config_values.var_configs["variables"] %}

{%- endif %}


dag = DAG(
    dag_id='{{ config_data["dag_id"] }}',
    {%- if dag_variables.valid_default_args %}
    default_args=default_args,
    {%- endif %}
    schedule={{ (config_data.get("schedule") or config_data.get("schedule_interval")) | tojson if config_data.get("schedule") != "None" and config_data.get("schedule_interval") != "None" else None }},
    description='{{ config_data.get("description") }}',
    {{ render_optional_param(config_data, 'max_active_runs', 1) }}
    {{ render_optional_param(config_data, 'catchup', False) }}
    {{ render_optional_param(config_data, 'is_paused_upon_creation', True) }}
    {{ render_optional_param(config_data, 'dagrun_timeout', "timedelta(hours=6)") }}
    {{ render_optional_param(config_data, 'tags', ['composer-templates']) }}
    {{ render_optional_param(config_data, 'start_date', "datetime(2024, 12, 1)") }}
    {{ render_optional_param(config_data, 'end_date', "datetime(2024, 12, 1)") }}
    {{- render_optional_param(config_data, 'max_active_tasks') }}
    {{- render_optional_param(config_data, 'on_failure_callback') }}
    {{ render_optional_param(config_data, 'on_success_callback') }}
)


with dag:
    {#- Start: Processes 'tasks' from YAML  #}
    {%- if config_data.get('tasks') and config_data['tasks'] %}
    {%- for task in config_data['tasks'] %}
        {{ render_task(task, dag_variables) }}
    {%- endfor %}
    {%- endif %}
    {#- End #}

    {#- Start: Processes 'task_groups' from YAML  #}
    {%- if config_data.get('task_groups') and config_data['task_groups'] %}
    {%- for group in config_data['task_groups'] %}
        {{ render_task_group(group, dag_variables) }}
    {%- endfor %}
    {%- endif %}
    {#- End #}

    {#- Start: Processes dependencies based on 'depends_on' from YAML  #}
    {% include 'dependencies.template' -%}
    {# End #}
